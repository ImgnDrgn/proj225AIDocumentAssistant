# 模型选择

选取了`uer/roberta-base-cinese-extractive-qa`、`lim68/qa-roberta-base-chiese-extractive`、`timpal0l/mdeberta-v3-base-squad2`三个模型进行了微调，得到了一下数据

主要对比参数为`train_loss`，值越小训练效果一般而言越好

|model name|train_runtime|train_samples_per_second|train_steps_per_second|**train_loss**|epoch|
|:---:     |:---:        |:---:                   |:---:                 |:---:         |:---:|
|`lim68/qa-roberta-base-chiese-extractive`|3188.1479|11.173|2.794|**2.8489648055130883**|3.0  |
|`timpal0l/mdeberta-v3-base-squad2`|4511.445|7.795|1.949|**2.6428933777554806**|3.0           |
|`uer/roberta-base-cinese-extractive-qa`|1629.4328|21.865|5.466|**2.8305770402486257**|3.0    |

从上表数据上看，`timpal0l/mdeberta-v3-base-squad2`在三者中具有明显优势，因此决定采用该模型作为后续使用的模型
